# No dumb questions: Are there unthinkable thoughts?

I recently found myself on a Wikipedia page entitled [List of animals by number of neurons](https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons). I was surprised to learn that starfish have about 500 neurons, which is only double the neurons of the microscopic [tardigrade](https://en.wikipedia.org/wiki/Tardigrade). Is that even enough neurons to have a sensation of thought? What _is_ the sensation of thought? In any case, I figured, those poor things will never experience even a fraction of the thoughts that a human can have in the span of a single day. That left me with a nagging question, though.

> Are there thoughts that no human will ever be able to think?

On one hand, thoughts are usually characterized (somewhat anthropocentrically) by the fact that someone, you know, _thought_ them. I mean, a starfish definitely has no idea of the thoughts that lay beyond its simple echinodermic existence, so how could we?

Call me overconfident, but I have more faith in humans. With our self-awareness and power for abstraction, I think we can chip away at some different angles of this question and gain a vague intuition for what lies beyond. It's like looking at a black hole; there's literally nothing there to see– no photons to reach your eyes– but by observing all the stuff _around it_, we know it's there, and that's pretty cool.

So with that said, let's think the unthinkable!

## Thought and experience

We're obviously dealing with a very thorny and layered question, but just to start somewhere, let's start with something we've all experienced: experiences. While I don't claim to know the exact relationship between experiences and thoughts, allow me to fulfill my quota of "one controversial opinion per essay" by asserting that there _is_ a relationship. Jokes aside, one could argue that all thoughts are rooted, somehow, in prior experience. Immediately after writing that sentence, I fell down a very deep rabbit hole called "Would a brain that never received any stimulus experience thought?" which I'm just going to have to put aside for now. It's still safe to say that most of your thoughts _draw from_ your experiences, :hook["real"]{id="real"} or imagined.

Let's take an apple, the poster child of thinkable objects. Thinking about an apple is pretty easy. If you're a visual thinker, you can just picture an apple. Visual thinking isn't the only way to go, though. If it was, we'd have to argue that people with [aphantasia](https://en.wikipedia.org/wiki/Aphantasia) can't think of things, which is a loser take. Personally, if you asked me to think of an apple, the experience is more like a vague _concept_ of an apple being brought to the forefront of my mind, primed to answer questions like "what does one taste like?" or "could you build a house out of them?". I've also had plenty of experiences with apples, so it's equally easy to think about apples rolling down hills, people bobbing for apples, and so on.

It goes a step further; I've never seen a blue apple, in person or otherwise, but it's just as easy to conceptualize a blue apple. Why? I've seen blue things, and I've seen apples, and I've seen things be different colors, so bada-bing, bada-boom, blue apple.

We can take this yet another step further, beyond the realm of things I haven't experienced to the realm of things no human :hook[could possibly experience]{id="possibly-experience"}, like a cow jumping over the moon or a person walking through a wall. Impossible to think? Not in the slightest; I just did, and you did as well. I can picture a cow jumping over the moon because I've seen cows, animals jumping, and the moon. Even if I hadn't seen characters clipping through walls in video games, I could draw from my experience of liquids to imagine someone walking through a wall as if it were a vertical pool of viscous wall-like liquid.

This feels like :hook[second nature]{id="second-nature"} to us (because it is), but it's actually extremely deep. Our capability to imagine impossibilities by freely combining concepts is one of our greatest strengths. In fact, without it, we wouldn't have the rich language that sets us apart from other animals. As Professor Dr. Eric Reuland writes in his paper [_Language and imagination: Evolutionary explorations_](https://pubmed.ncbi.nlm.nih.gov/28041788/):

> Given [our linguistic tools], we have recursive combinability and principles enabling the interpretation of the structures produced. The interpretation rules are insensitive to plausibility or implausibility, sense or nonsense. They as easily combine _brown_ with _bear_ as _square_ with _circle_ or _white_ (or _black_) with _hole_. A stone may jump, a mountain may hear. In short what we have is _imagination unleashed_.

So, if our brain is capable of combining concepts to create essentially infinitely many imagined realities, what could possibly stop us?

### The speed of thought

Let's travel 10,000 years back in time to 8,000 BC and find a "bustling" agricultural civilization nestled in the [Fertile Crescent](https://en.wikipedia.org/wiki/Fertile_Crescent). You think, well, here are a bunch of humans who have brains essentially identical to ours (evolutionarily speaking) and are capable of full-fledged spoken language. Now, let's just wait for one of them to randomly synthesize enough thoughts to stumble upon the modern-day design of the internet. Just to make it a little more tractible, say we come up with a description of the internet that feels sufficiently accurate while being _theoretically_ possible to grasp by a person with 8,000 BC technology. I made an attempt for the sake of illustration; read it if you want, but it's mostly a proof of concept.

> **The internet for the Stone Age polymath**
>
> First, we must understand the idea of code. A code is essentially a way of using _symbols_ to _represent_ something. Once you understand this, you can invent _written language_, which uses an _alphabet_ (a set of symbols) to represent spoken language. Similarly with numbers to represent the quantity of things. Now, consider a message which says `erase all the letter "e"s in this message`. If you were to follow this instruction, you would modify the symbols in the message and wind up with `ras all th lttr ""s in this mssag`. This illustrates the point that symbols can be _both_ "just" symbols _and_ (once interpreted) instructions for modifying symbols.
>
> Once you grasp this concept, you can begin to conceptualize a Turing Machine (which is better described [elsewhere](https://www.quantamagazine.org/alan-turings-most-important-machine-was-never-built-20230503/), but which doesn't require any fancy mathematics or material science to imagine). Once you've got the Turing Machine down, you can start to imagine that you have a physical material that allows you to represent symbols; for example, a magical material that can be precisely controlled to have two states: an "off" and "on" state. We'll call one chunk of this material a _bit_. Just like the "e" example, these bits can be used both as data (for example, to represent a message in written language) and instructions (for example, a procedure for moving a message from the bits its currently stored on to another set of bits). Building on this contept, you can arrive at the idea of a _programmable computer_.
>
> Now, let's say you have a computer, and your friend has a computer in another distant village. You have a message stored on your computer that you want to send to your friend. You could connect your computers with a long wire, which is made of a material that can turn "off" or "on", just like bits. Since your computers are programmable, you can write instructions to take the message on your computer and flash the wire "on" and "off" to "read" out the message on your computer. Your friend's computer would have a similar program to "read" the wire and copy the pattern of "off"s and "on"s onto its own bits. Now, in essence, you have the internet!

Obviously, there are tweaks that could be made. For example, I left out the idea of keyboards and monitors, and I didn't mention how wires can be replaced with wireless technology, but the core idea is there. This description also doesn't make any mention of electricity, which I think is acceptable because the exact mechanics of electricity is :hook[low-level enough to be an implementation detail of computers and the internet]{id="implementation-detail"}.

I'm not sure if I even have to say this, but the odds that a Neolithic person living in Neolithic times could make these conceptual breakthroughs is _astronomically_ unlikely, and I'm even tempted to claim that it's categorically _impossible_. That, even if you simulated infinitely many neolithic agricultural societies, there wouldn't be _one_ human that could conceptualize the idea of the internet in this way. I don't have any hard facts to back up that stronger claim, but if you don't believe me, try it and get back to me.

I mean, the _second step_ in that sequence– recognizing that symbols can be used to represent spoken language– took about another six _thousand_ years from the Stone Age to work out. While we can't say for sure that _no one_ had the idea of written language, six _thousand_ years without evidence of writing sure says something.

:hook[Ideas follow the laws of natural selection]{id="memetics"}, and as such, complex concepts just take _time_ and _generations_ to pop into existence. Just as :hook[humans didn't suddenly pop into existence]{id="evolution"} in a vacuum, but evolved over millions of years of natural selection, the thought of an internet made of computers was developed gradually over thousands of years, each generation of great minds standing atop the shoulders of the society that came before.

I think about Isaac Newton a lot in the context of being ahead of one's time. Newton's genius was pretty hard to understate. Over the course of the eight decades of his life, he:

- Generalized the binomial theorem from positive integers to all real numbers
- Invented the reflecting telescope
- Invented calculus
- Published _Principia Mathematica_, which laid out the laws of motion _and_ the idea of universal gravitation
- Advanced statistical analysis with his method of least squares
- Made the first attempt to reconcile the wave- and particle-like properties of light
- Anticipated the idea of an electric field
- Refined the scientific method

And a whole lot more that I probably forgot. But for all his genius, he probably couldn't have been able to formulate quantum field theory, or general relativity, or predict the existence of black holes, or prove Fermat's Last Theorem. The stage was set, so to speak, for Newton to help push humanity from the Scientific Revolution into the Enlightenment, but the time was not right for modern physics or ring theory. Genius only gets you so far. So, assuming humans continue to exist in 10,000 years (which I highly doubt), the concepts familiar to our descendants in the year 22025 would be truly unthinkable to us now, with our current understanding of the universe.

That sums up _one_ potential answer to the question of, "Are there unthinkable thoughts?", which is, "Yes, if the concepts require too much evolution from current concepts". Or, more poetically, "Yes, if getting there would exceed the speed of thought". Now, let's take a look at a different angle: experiences that our brains just aren't wired to imagine.

## Brain software and hardware

Most computers we’re familiar with have both hardware and software. The hardware includes the physical components that literally make up the computer, like the CPU, RAM, disk, motherboard, and peripherals like the monitor and speakers. We can also write out sets of instructions, or programs, that tell the hardware what to do. These programs constitute the software of the computer. In this way, two computers with the same hardware can be programmed to do extremely different things.

In addition to distinguishing between hardware and software, you could identify multiple _layers_ of software in a computer, ranging from "low-level" (close to the hardware) to "high-level" (abstracted from the hardware). The lowest layer would probably be the assembler, which turns :hook[assembly language]{id="assembly"} into `1`s and `0`s that the CPU can execute. The next lowest level software above that would be the compiler, which turns human-readable code into assembly, and somewhere above that, we’d find the operating system, which is the most user-friendly way to interface with the computer.

These higher levels of software make the hardware easier to work with at the expense of flexibility. For example, the operating system won’t let you write so many files that you overwrite the memory containing the instructions for the operating system itself, even though the hardware technically permits it.

The brain can be understood similarly. The "hardware" of our brain would be our neurons, as well as the laws of physics that govern the chemistry that governs those neurons. Dependent on that, we have various (fuzzy) layers of mental "software". Obviously, these different mental levels of cognition can't be teased apart as easily as the CPU from the motherboard, but some brain functions certainly seem lower-level than others.

For example, there are parts of your brain (notably the brain stem) that are responsible for regulating your heart rate and breathing rate. These are very low-level functions. You can become conscious of your breathing and :hook[choose to hold your breath longer than average]{id="breath"} ("you" referring to the part of your brain responsible for your high-level sense of self and agency), but ultimately, your brain stem has the final say and will take over to prevent you from dying of hypoxia.

Cutting to the chase: while you can change the software of your brain through conscious thought and experiences, there's also mental hardware, which is much less malleable. Just like you can’t program a regular computer to be a quantum computer, you can’t think your way into, say, conceptualizing the fourth dimension.

Let's elaborate on that.

### The fourth dimension?

Consider your eyes. The eye gets a (more or less) two-dimensional image of the world. I say that because all our brain has to work with are neural signals from a field of cones that get stimulated by different wavelengths of light. Unlike radar, where you send _and_ receive a signal and measure how long the round-trip took, the cones in our eyes have no idea how long it took for light to reach it. In other words, there's no _direct_ depth measurement. To make matters even more two-dimensional, our eyes rest only a few inches apart on the plane of our face, meaning we can usually only see at most _half_ of an object at one given time.

So, if we've never seen every side of an object at once, why do we experience the world as a three-dimensional place with three-dimensional things, instead of a two-dimensional screen of moving pictures? It goes beyond the fact that we have :hook[two eyes]{id="two-eyes"}; the visual processing part of our brain is hard-wired to use certain visual cues to construct a three-dimensional model of the world from these :hook[excited cones]{id="band"}. This automatic "lifting" of visual information to three dimensions allows us to look at a video, or an image, or even a drawing, and perceive depth with no effort necessary. Quite the opposite: it's basically impossible to _not_ see things in three dimensions. That said, let's try to see things in four dimensions.

#### Picturing the fourth dimension

We can actually learn a lot of things about the fourth dimension just by making connections between lower dimensions. I’ll go through a few of them.

As three dimensional beings, we can look at a 2D object and see _all_ its sides at once, including the inside of the object. It's all "laid out in front of us". In our three-dimensional world, a single viewpoint is restricted to seeing at most half of an object at a time, and the inside is hidden from view. In the fourth dimension, then, we could look at a 3D object and easily see _all_ of its sides at once, as well as its contents. Picture a box in front of you, with things inside. If you were a fourth-dimensional being, you could see all six sides of the box, as well as the contents of the box. You could also see every side of each item in the box, and their insides. It would all be laid out in front of you.

We can discover some additional details by generalizing familiar geometry. For instance, the amount of space taken up by a line is just the length of the line. The amount of space taken up by a square is its area, which is the side length squared. Similarly, the volume of a cube is the edge length cubed. Generalizing further, the _hypervolume_ of a tesseract (a four-dimensional cube) would be the edge length raised to the fourth power.

Here's another fact: a line has 2 sides, a square has 4, and a cube has 6 faces, so a tesseract would have 8 "faces", or _cells_ (as they're called).

One more: if you picked two endpoints of a line (there’s only one choice), they would be separated by one edge, namely, the line itself. On a square, the most edges you could find between any two vertices is two. On a cube, that number is three. Consequently, on a tesseract, the most number of edges separating two vertices would be four.

Surely, given all this information, you could picture a tesseract in all its four-dimensional glory?

Clearly, no amount of describing the properties of a fourth spatial dimension would enable us to _actually_ conceptualize it with the same level of vividness that we can grasp the third dimension. Although some people have dedicated a lot of time to the pursuit of fourth-dimensional intuition, I would argue that these people are dancing _around_ four-dimensional thoughts, as closely as possible without actually experiencing it. You could, like I just did, read through the [Wikipedia page for Tesseract](https://en.wikipedia.org/wiki/Tesseract) and go like "uh huh, yep, makes sense", but actual four-dimensional thoughts would still remain just out of reach.

This is categorically different from things like cows jumping over the moon, which we also have no experience of. It's not just that we've never experienced the fourth dimension, it's that the _hardware_ of our brain– which went all-in on the third dimension– is working directly against us. You could make a similar argument for other sensations that humans don't experience, like seeing infrared / ultraviolet light, or sensing magnetic fields. But I think higher dimensions are a much more satisfying candidate for "unthinkable thoughts" because they're _so close_ to our regular thoughts, and at the same time, so far away that the word "far" doesn't even apply.

> **Addendum**
>
> After writing this essay and coming back to this section, I've softened my position a little on the subject of whether higher dimensions are possible to fully conceptualize. I think my main point mostly stands: that your brain has never perceived _anything_ four-dimensional (spatially), which makes it fundamentally different from the other "impossible" scenarios we can construct in our heads. But we do have experience with time, which isn't a bad analogy for four spatial dimensions, and I think it's probably possible to amass so much intuition about the fourth dimension that it feels like second nature. So, pick your definition of "thought".

## Unreachable levels of abstraction

I'd like to call your attention to a wonderful little principle called the pigeonhole principle. If you're not aware of it, this is essentially what it says:

> **Pigeonhole principle**: Imagine you have `N` things and `M` containers. If `N > M`, then at least one container will have more than one thing in it. Similarly, if `N < M`, then at least one container will have no things in it.

You could prove this fact from first principles, but there's really no need, since it's so obviously _true_. With this simple principle, you can prove that there must be two people in London who have the same number of hairs on their head, or that, in a situation where people are shaking hands, there will always be at least two people who have :hook[shaken the same number of hands]{id="shake"}.

Let's go back to our echinodermic friend, the starfish, with its 500 neurons. Could a starfish ever conceptualize the pigeonhole principle? I strongly doubt it. Even if a particular starfish got lots of experience putting things in containers (already doubtful), the idea that it would generalize those experiences to a "principle", with all of its 500 neurons, is fantasy. I don't know where the line is, but it's definitely above 500.

Let's jump way up the neurological pecking order and consider chimpanzees. Could a _chimp_ conceptualize the pigeonhole principle? It feels harder to say "no" right away. I'm certain that a chimp understands the concept of "you can't fit too many things in a container". But the pigeonhole principle deals with an idea more discrete and precise than that, and I'm not immediately sure that a :hook[chimp can really understand]{id="chimp"} the general principle. Maybe they can, maybe they can't.

So, on the scale of "understands the pigeonhole principle", we definitely have a spectrum from starfish to humans. This raises an obvious question: why? Although having a sufficient number of neurons is definitely a prerequisite, it's clearly not _the_ deciding factor. It seems more related to humans' capacity for _symbolic thought_: the ability to _refer_ to things as concepts, combine concepts freely, abstract patterns from reality, generalize those patterns, and apply them to new contexts. This ability _seems_ pretty unique to humans.

That's definitely a morale booster, and could be taken to mean that humans "won the game" in terms of intelligence, and that we really are capable of conceptualizing any abstract concept or pattern. But– while I can't prove otherwise– I have my suspicions.

### Adding and multiplying

In my [formal systems](https://worldsworstdetective.com/formal-systems) essay, I made a passing comment about how, although we have a pretty much perfect understanding of addition and multiplication by themselves, we don’t yet fully understand how they interact with each other. This gets at my meaning of the word "understand".

> **Levels of understanding of addition and multiplication**
>
> - **Basic understanding**: Know how to compute the sum of products and the product of sums.
> - **Medium understanding**: Explain why every number greater than 1 has a unique prime factorization, and why there are an infinite number of primes.
> - **Advanced understanding**: Explain why there are no integer solutions to the equation `a^n + b^n = c^n` when `n >= 2` ([Fermat's Last Theorem](https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem)).
> - **Not yet understood**: Explain why there are (or aren't) infinitely many [twin primes](https://en.wikipedia.org/wiki/Twin_prime#Twin_prime_conjecture), or why every even number can(’t) be [expressed as the sum of two primes](https://en.wikipedia.org/wiki/Goldbach%27s_conjecture), or why there are(n’t) [odd perfect numbers](https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers), or why (not) every positive integer yields 1 after sufficient applications of the [Collatz rule](https://en.wikipedia.org/wiki/Collatz_conjecture).

Who would’ve guessed there could be so much mystery surrounding the interaction of addition and multiplication? Just to illustrate the point, consider the fact that Fermat's Last Theorem was asserted in 1637, but wasn't proven until _358 years later_ by Andrew Wiles in 1994. Some of the mathematical results Wiles used to construct his proof weren't even discovered until the 1980s (speaking of the "speed of thought").

With that in mind, it feels very possible that we've already proposed conjectures that won't be proven for a _thousand_ years. But what about the extreme? Are there "simple seeming" facts about numbers that we'll never be able to determine?

If you've heard of [Gödel's Incompleteness Theorem](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems) (GIT), you're probably thinking this is when I'll introduce it. That was my original plan, but applying GIT to the human brain is always a sketchy affair, and I got about 6,000 words deep when I realized that it wasn't worth it. So, I'll just describe my intuition and leave ol' [Kurt](https://en.wikipedia.org/wiki/Kurt_G%C3%B6del) alone for now.

### Chaos in the patterns in the chaos in the patterns...

We've discussed starfish and chimps, but it's time to bring in the beavers– specifically, busy ones. In computer science, the Busy Beaver problem is a challenge involving finding :hook[Turing machines]{id="turing"} that can keep themselves "occupied" for the longest time (the most steps) _without_ running forever. Turing machines vying for the title of Busy Beaver will start out on a blank tape of all `0`s, and can only write `0`s or `1`s. Additionally, Turing machines are broken up into different "weight classes" by their number of internal states. The Busy Beaver with _n_ states is called BB(n). Let's take a look at BB(2), the Turing machine with two internal states which runs for the most number of steps before terminating.

```
BB(2)

if in state A:
  if reading 0: write a 1, move right, and switch to state B
  if reading 1: write a 1, move left, and switch to state B
if in state B:
  if reading 0: write a 1, move left, and switch to state A
  if reading 1: write a 1, move right, and halt
```

This critter runs for a total of 6 steps, leaving in its wake a tidy little group of four `1`s. The busiest Turing machine with 3 internal states, BB(3), keeps itself occupied for 14 steps. BB(4) rages against the dying of the light but expires after 107 steps. Mathematician Allen Brady discovered this Turing machine in 1966, but couldn't prove that it was _the_ fourth Busy Beaver until 1974. The fifth Busy Beaver, though, was a completely different story.

Allen Brady himself was skeptical that BB(5) could even be proved. He wrote:

> Nature has probably embedded among the five-state holdout machines one or more problems as illusive as the Goldbach Conjecture. Or, in other terms, there will likely be nonstopping recursive patterns which are beyond our powers of recognition.

But he was wrong. In mid-2024, through the spectular efforts of an organized online community of amateur mathematicians, the fifth busy beaver was proven to run for a mind-boggling 47,176,870 steps. If you'd like to learn more, Quanta Magazine has a [fantastic article](https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/) about the whole story with all its twists and turns. It's actually one of my favorite pieces of scientific journalism.

We can visualize the outputs of Turing machines by representing the tape in each step of its computation as a sequence of rows, where colored pixels are `1`s and black pixels are `0`s. Take a look at a small portion of a five-state Turing machine that was shown to run forever (rotated 90 degrees for visibility):

![A chaotic but oddly beautiful pattern of black and white pixels](unthinkable/infinite-tm.png "The patterned chaos of a nonterminating Turing machine. From Quanta Magazine.")

I don't know about you, but looking at stuff like this really makes me awe-struck by the beauty of the universe. It looks like an alien world.

So, shall we get on with finding BB(6)? Well, I'm not sure we even have a _word_ that describes how much harder BB(6) is compared to BB(5). To quote from the Quanta article:

> Meanwhile, part of the team has moved on to the next beaver. But just four days ago, [two contributors] discovered a barrier for BB(6) that seems insurmountable: a six-rule machine whose halting problem resembles a famously intractable math problem called the Collatz conjecture. [...] "It’s conceivable that this is the last busy beaver number that we will ever know."

For that matter, it's been proved that solving BB(27) is as hard as another famously unsolved problem called the [Goldbach conjecture](https://en.wikipedia.org/wiki/Goldbach%27s_conjecture) (which was mentioned in passing earlier), and that finding `B(744)` would be as hard as proving the [Riemann Hypothesis](https://en.wikipedia.org/wiki/Riemann_hypothesis), widely considered to be the "Holy Grail of Mathematics".

The important point is that finding each successive busy beaver is _qualitatively_ different from (and harder than) any that came before. Each one will require new levels of abstraction to recognize the patterns in the chaos.

This idea of "patterns of chaos" is, I think, a very beautiful one. One could argue that the course of human scientific progress has been the history of finding patterns in chaos, and then noticing the chaos _in_ those patterns, until we once again find a pattern which explains those chaotic patterns of chaos, until we notice the chaos in _those_ patterns, and so on. Can we keep on finding the patterns... forever? If we do, will there be a point where we no longer see chaos, only patterns?

I don't think so. I have no proof, just faith. I think there are patterns in our universe which exist on levels of abstraction that our brain (which, as a reminder, evolved primarily to stay alive and tell other monkeys where the bananas are) will never be able to reach. At some point, we'll run into the limit of the "speed of thought" combined with humanity's finite existence combined with the maximum information density of the brain.

# This thought cannot be thunk

Thus concludes my answer to the question of "Are there thoughts that can't be thunk?". Because of the way _my_ brain is wired, this essay turned out more technical than I was initially going for, mostly because I had a hard time convincing myself that other non-technical thoughts had any real limitations that could be described with any level of precision.

To be optimistic, though, the fact that it was so damn difficult to write a compelling argument for any (interesting) limitation of the brain is uplifting in its own way. So, go forth and think!

:footnote[I'm putting "real" in quotes because, in the context of our perception, everything is subjective. There's no separate compartments in your brain for the stuff that "really" happened and the stuff you read in books or saw in movies. Sometimes it's hard to tell them apart.]{id="real"}
:footnote[Just like my previous footnote, there's no real distinction between possible and impossible experiences because of fiction (or hallucinogens), but that's the point, really.]{id="possibly-experience"}
:footnote[All of a sudden, I got curious about what _first_ nature is supposed to be. Interestingly, it turns out that "second" here actually refers to "following" nature, kind of like how you might "second" an opinion. It comes from the latin _secundum naturum_, and is contrasted with _super naturum_ ("above nature") and _contra naturum_ ("against nature").]{id="second-nature"}
:footnote[Sometimes the connection between the symbol and thing is very clear, like "rock", but other times it's much more tenuous, like "beautification".]{id="loosely"}
:footnote[This sentence might get me into a lot of trouble.]{id="implementation-detail"}
:footnote[See: [memetics](https://en.wikipedia.org/wiki/Memetics), or this classic [CGP Grey video](https://www.youtube.com/watch?v=rE3j_RHkqJc).]{id="memetics"}
:footnote[Controversial opinion #2.]{id="evolution"}
:footnote[This statement led me to the Wikipedia page for [Diving reflex](https://en.wikipedia.org/wiki/Diving_reflex), which was a fascinating read. Turns out that our brain's hardware also includes instructions for subconsciously directing more blood to vital organs when our face is submerged and our nostrils fill with water. Crazy.]{id="breath"}
:footnote[Contrary to popular opinion, depth perception is not dependent on having two eyes; although there are many important visual cues that [do require them](https://en.wikipedia.org/wiki/Stereopsis), there are [plenty of others](https://www.wtamu.edu/~cbaird/sq/2023/07/28/why-does-a-person-with-only-one-working-eye-have-zero-depth-perception/) that don't.]{id="two-eyes"}
:footnote[Band name.]{id="band"}
:footnote[These are (barely) human-readable instructions for the CPU to execute, like `MOV EAX, 5`, which means to move the value of 5 into the register called `EAX`.]{id="assembly"}
:footnote[Proof: Suppose there's `N` people, or "pigeons". The "holes" in this analogy are the number of hands shaken. On first inspection, there seems to be `N` holes, since one can shake hands with between `0` and `N-1` people. But once you realize that it's impossible for one person to shake hands with everyone while somebody has shaken hands with no one, it's impossible for _both_ the `0` and `N-1` buckets to be occupied at the same time. Then, since there are `N` people and at most `N-1` available holes, by the pigeonhole principle, at least two people will have shaken the same number of hands.]{id="shake"}
:footnote[I spent way too long trying to think of an experimental design that could test this, and came up empty-handed. It seems hard to conclusively demonstrate that an animal understands something is _impossible_. If you have ideas, though, I'd love to hear them! You can find my contact [here](https://marcos.ac).]{id="chimp"}
:footnote[If you're unfamiliar with Turing machines, they're actually pretty easy to define. You could check out [this quick 5-minute video](https://www.youtube.com/watch?v=dNRDvLACg5Q) to get the idea.]{id="turing"}
